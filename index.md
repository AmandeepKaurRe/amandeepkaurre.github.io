---
layout: default
description: I'm Amandeep Kaur and I work on Computer Vision/Remote Sensing. More details inside!
---

![i_am_a_fox](./img/people/aman.jpeg){: style="float: right; margin: 0px 20px; width: 250px; border-radius: 50%" name="fox"}

I am Amandeep Kaur (Reehal), a PhD student at [Arizona State University](https://www.asu.edu/), advised by [Dr. Hannah Kerner](https://hannah-rae.github.io/). My research focuses on understanding the impact of data distribution in large-scale pretraining for foundation models. I am particularly interested in satellite imagery, where factors such as geographic coverage can be systematically controlled, providing a unique setting to study these effects. I am also exploring approaches to identify and analyze concepts that advance model interpretability.

Previously, as part of Google Deepmind, I was working on AMED(Agricultural Monitoring and Event Detection), creating ML/DL models to generate pan-India crop covers 
for top-10 Indian crops using Sentinel1-2, under the guidance of [Alok Talekar](https://research.google/people/106902/?&type=google) and 
[Dr. Gaurav Aggarwal](https://scholar.google.com/citations?user=9XiIwDQAAAAJ&hl=en). 

Before Google, I was at IIIT-D,
pursuing my Bachelor's in CSE where I first got into research. I had the pleasure of working with [Dr Rahul Purandare](https://scholar.google.com/citations?user=_OLz-J0AAAAJ&hl=en) 
in the summer of my 2nd year. Then under the guidance of [Dr. Jainendra Shukla](https://scholar.google.es/citations?user=QCZleNQAAAAJ&hl=en), I did an independent project where 
I created a system to collect audio speech samples from Indian students for our project on improving English pronunciation of Indian students. As part of my Bachelor's Thesis, 
I worked on improving a head gesture guided typing system for people with limited body motion, under the supervision 
of [Dr. Rajiv Ratn Shah](https://scholar.google.com.sg/citations?user=WAChZv4AAAAJ&hl=en).


## <span style="color:darkblue">News </span>

__2025__
* <span style="color:#7fa827">Update:</span> [Oral] at AGU'25. Going to talk about impact of pretraining distribution on the GeoFoundational model, SatMAE. 

__2024__
* <span style="color:#7fa827">First(?):</span> Started doctorate at Arizona State University
* <span style="color:#7fa827">First:</span> [Oral] at EGU'24. Spoke about detecting field level crop seasons. 

__2023__
* <span style="color:#7fa827">First:</span> [Paper](https://agu.confex.com/agu/fm23/meetingapp.cgi/Paper/1286158) accepted to AGU'23. 
* <span style="color:#7fa827">First:</span> [Oral] at AGU'23. Spoke about detecting field level crop seasons. 

__2022__
* <span style="color:#7fa827">First:</span> Job at Google Deepmind(previously, Google Research India). Worked with Anthrokrishi to study Indian farm fields using satellites. My google maps is always set to satellite view XD
* <span style="color:#7fa827">First:</span> Gave a [talk](https://www.youtube.com/watch?v=lCFbbOgsm9I&t=1613s) presenting Anthrokrishi's work at Google for India(G4I'22).

__2021__
* <span style="color:#7fa827">First:</span> Interned at Royal Bank of Scotland(Natwest Group) as a software development intern. Did a lot of Java. 
* <span style="color:#7fa827">AI for Social Good:</span> Began my two-semester Bachelor's thesis, worked on assistive typing technology which used head gestures. Met transformers for the first time.

__2020__
* <span style="color:#7fa827">AI for Social Good:</span> Woked with the [Human Machine Interaction Lab, IIITD](https://hmi.iiitd.edu.in/) to build a system to help improve Indian students english pronunciations. Ask me about phonemes, utterances and speech in kids. 

__2019__
* <span style="color:#7fa827">First:</span> Research experience as part of a software development intern in the [Program analysis Group, IIITD](https://pag.iiitd.edu.in/). :D
